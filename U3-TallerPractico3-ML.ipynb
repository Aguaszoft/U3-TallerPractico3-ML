{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# CNN"],"metadata":{"id":"AW1nn2N_fxEo"}},{"cell_type":"markdown","source":["## Red entrenada"],"metadata":{"id":"80DFayOReTAU"}},{"cell_type":"markdown","source":["Importando bibliotecas"],"metadata":{"id":"cAiYnaAFJOQK"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms"],"metadata":{"id":"u4LVQWLDf5At","executionInfo":{"status":"ok","timestamp":1715823415263,"user_tz":300,"elapsed":14266,"user":{"displayName":"Enrique Vinicio Carrera","userId":"06410025932536792333"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Inicializando parámetros para el uso de la GPU"],"metadata":{"id":"xRty-7pTKE9f"}},{"cell_type":"code","source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","train_kwargs = {'batch_size': 500}\n","test_kwargs = {'batch_size': 500}\n","if use_cuda:\n","    cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n","    train_kwargs.update(cuda_kwargs)\n","    test_kwargs.update(cuda_kwargs)"],"metadata":{"id":"inYwwT0UJ0og","executionInfo":{"status":"ok","timestamp":1715823468047,"user_tz":300,"elapsed":246,"user":{"displayName":"Enrique Vinicio Carrera","userId":"06410025932536792333"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["Descargando conjunto de datos (aplica transformaciones)"],"metadata":{"id":"YBtdMcg-Jfpl"}},{"cell_type":"code","source":["transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (0.3,)) ])\n","\n","dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transform)\n","dataset2 = datasets.MNIST('../data', train=False, transform=transform)\n","train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n","test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"],"metadata":{"id":"BGamiDO6Ja8M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715823496284,"user_tz":300,"elapsed":4495,"user":{"displayName":"Enrique Vinicio Carrera","userId":"06410025932536792333"}},"outputId":"562b2ac5-78ed-4f90-ba48-c55495001b19"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 15688213.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 507734.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 4359682.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 3037877.34it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["## Red convolucional"],"metadata":{"id":"wwQ9i17xf7nE"}},{"cell_type":"markdown","source":["Definición del modelo"],"metadata":{"id":"W0jtjhDzaFvs"}},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n","        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(9216, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.max_pool2d(x, 2)\n","        x = self.dropout1(x)\n","        x = torch.flatten(x, 1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return F.log_softmax(x, dim=1)\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 20 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch,\n","                batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","    test_loss /= len(test_loader.dataset)\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(test_loss,\n","        correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"],"metadata":{"id":"r5W2BMZFgFIM","executionInfo":{"status":"ok","timestamp":1715823639651,"user_tz":300,"elapsed":261,"user":{"displayName":"Enrique Vinicio Carrera","userId":"06410025932536792333"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Main execution"],"metadata":{"id":"j6wY0NizgLLV"}},{"cell_type":"code","metadata":{"id":"_Y_qZaZr_Gn5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715823741075,"user_tz":300,"elapsed":80345,"user":{"displayName":"Enrique Vinicio Carrera","userId":"06410025932536792333"}},"outputId":"d7ccd970-04e5-4e1d-e1ef-cd31c151c6a7"},"source":["model = Net().to(device)\n","optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n","for epoch in range(5):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)\n","    scheduler.step()"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.311967\n","Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.491292\n","Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.280689\n","Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.223724\n","Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.208582\n","Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.160930\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0703, Accuracy: 9773/10000 (97.73%)\n","\n","Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.103978\n","Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.125467\n","Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.143290\n","Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.083240\n","Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.065785\n","Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.141876\n","\n","Test set: Average loss: 0.0435, Accuracy: 9861/10000 (98.61%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.086841\n","Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.076105\n","Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.076107\n","Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.105688\n","Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.091127\n","Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.093661\n","\n","Test set: Average loss: 0.0388, Accuracy: 9862/10000 (98.62%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.084058\n","Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.069267\n","Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.070628\n","Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.059437\n","Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.105977\n","Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.071147\n","\n","Test set: Average loss: 0.0341, Accuracy: 9877/10000 (98.77%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.081999\n","Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.059381\n","Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.045492\n","Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.041094\n","Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.044020\n","Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.032397\n","\n","Test set: Average loss: 0.0318, Accuracy: 9882/10000 (98.82%)\n","\n"]}]},{"cell_type":"markdown","source":["Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.046530\n","Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.058467\n","Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.041516\n","Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.047902\n","Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.043068\n","Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.020944\n","\n","Test set: Average loss: 0.0321, Accuracy: 9889/10000 (98.89%)"],"metadata":{"id":"vhE-HKvnxitp"}},{"cell_type":"markdown","source":["## Tarea 1"],"metadata":{"id":"GeB8-XUTLPoF"}},{"cell_type":"markdown","source":["Entrenar la red convolucional pero esta vez con el conjunto de datos Fashion-MNIST"],"metadata":{"id":"_2oBa42yMlNx"}},{"cell_type":"code","source":["transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,), (0.3,)) ])\n","\n","dataset1 = datasets.FashionMNIST('../data', train=True, download=True, transform=transform)\n","dataset2 = datasets.FashionMNIST('../data', train=False, transform=transform)\n","train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n","test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"],"metadata":{"id":"4kW1MXWoLTgr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO\n"],"metadata":{"id":"tTera7koMxNh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Reportar el desempeño alcanzado con la red convolucional en el conjunto de datos Fashion-MNIST"],"metadata":{"id":"C2I3IVzFM0uv"}},{"cell_type":"markdown","source":["## Tarea 2"],"metadata":{"id":"RPIvIL8ULhAE"}},{"cell_type":"markdown","source":["Entrenar la red convolucional pero esta vez con el conjunto de datos CIFAR10"],"metadata":{"id":"5qsFmmvEsffz"}},{"cell_type":"code","source":["transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5,), (0.3,0.3,0.3,)) ])\n","\n","dataset1 = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n","dataset2 = datasets.CIFAR10('../data', train=False, transform=transform)\n","train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n","test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n","\n","from torchvision.utils import make_grid\n","import matplotlib.pyplot as plt\n","for images, labels in train_loader:\n","    fig, ax = plt.subplots(figsize=(10, 10))\n","    ax.set_xticks([]); ax.set_yticks([])\n","    ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n","    break"],"metadata":{"id":"KEZUFrZOo6ht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TODO\n"],"metadata":{"id":"3G8MMNcYqN-q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Reportar el desempeño alcanzado con la red convolucional en el conjunto de datos CIFAR10"],"metadata":{"id":"kIipH5_cnebh"}}]}